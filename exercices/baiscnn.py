# -*- coding: utf-8 -*-
"""BaiscNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DZeNCxltno6x5v4xfEl2hd9XVkd-rsBR

# Import libs
"""

import numpy as np
#import matplotlib as plt
import pandas as pd
import pickle
import sklearn.datasets as datasets
from matplotlib import pyplot as plt

plt.rcParams['figure.figsize'] = (10,6)
plt.style.use('dark_background')

"""# Dataset

"""

x,y = datasets.make_moons(n_samples = 500, noise = 0.05)

print(f'{x.shape = }, {y.shape = }')

pd.DataFrame({'x_1': x[:,0], 'x_2': x[:, 1], 'y': y})

unique = np.unique(y, return_counts= True)
for label, qt_label in zip(unique[0], unique[1]):
    print(f'Label: {label}\t Counts: {qt_label}')

plt.scatter(x[:, 0], x[:, 1], c = y, s = 50, alpha = 0.5, cmap = 'cool')

"""# Modelo

"""

class Perceptron:
  def __init__(self, x: np.ndarray, y: np.ndarray, hidden_neurons: int = 10, output_neurons : int = 2):

    np.random.seed(8)
    self.x = x
    self.y = y
    self.hidden_neurons = hidden_neurons
    self.output_neurons = output_neurons
    self.input_neurons = self.x.shape[1]

    #Pesos e Baias
    self.W1 = np.random.randn(self.input_neurons, self.hidden_neurons) / np.sqrt(self.input_neurons)
    self.B1 = np.zeros((1, self.hidden_neurons))
    self.W2 = np.random.randn(self.hidden_neurons, self.output_neurons) / np.sqrt(self.hidden_neurons)
    self.B2 = np.zeros((1, self.output_neurons))
    self.model_dict = {'W1': self.W1, 'B1': self.B1, 'W2': self.W2, 'B2': self.B2 }
    self.z1 = 0
    self.f1 = 0

    pass

  def foward(self, x: np.ndarray) -> np.ndarray:
    # Equação da Reta
    self.z1 = x.dot(self.W1) + self.B1

    # Função de Ativação
    self.f1 = np.tanh(self.z1)

    # Equação da reta (2)
    z2 = self.f1.dot(self.W2) + self.B2

    # Softmax
    exp_values = np.exp(z2)
    softmax = exp_values/np.sum(exp_values, axis = 1, keepdims = True)
    return softmax

  def show_plot(self, predictions):
    if self.x.shape[1] != 2:
      return

    plt.scatter(self.x[:, 0], self.x[:, 1], c = predictions, s = 50, alpha = 0.5, cmap = 'cool')

  def loss(self, softmax):
    #Cross Entropy
    predictions = np.zeros(self.y.shape[0])
    for i,  correct_index in enumerate(self.y):
        predicted = softmax[i][correct_index]
        predictions[i] = predicted

    log_prob = -np.log(predicted)
    return log_prob/self.y.shape[0]

    pass

  def backpropagation(self, softmax: np.ndarray, learning_rate: float) -> None:
    delta2 = np.copy(softmax)
    delta2[range(x.shape[0]),y] -= 1

    dW2 = (self.f1.T).dot(delta2)
    dB2 = np.sum(delta2, axis = 0, keepdims=True)

    delta1 = delta2.dot(self.W2.T)*(1-np.power(np.tanh(self.z1),2))
    dW1 = (self.x.T).dot(delta1)
    dB1 = np.sum(delta1, axis = 0, keepdims=True)

    #update
    self.W1 += - learning_rate*dW1
    self.W2 += - learning_rate*dW2
    self.B1 += - learning_rate*dB1
    self.B2 += - learning_rate*dB2


  def fit(self, epochs: int, lr: float):

      for epoch in range(epochs):
        outputs = self.foward(self.x)
        loss = self.loss(outputs)
        self.backpropagation(outputs, lr)

        # Acurácia
        prediction = np.argmax(outputs, axis = 1)
        correct = (prediction == self.y).sum()
        accuracy = correct/self.y.shape[0]

        if int((epoch+1) % (epochs/10)) == 0:
          print(f'Epoch: [{epoch+1} / {epochs}] Accuracy: {accuracy:.3f} Loss: {loss.item():.4f}')

hidden_neurons = 10
output_neurons = 2
learning_rate = 0.002
epochs = 50

modelo = Perceptron(x,y, hidden_neurons = hidden_neurons, output_neurons=output_neurons)
result = modelo.fit(epochs, learning_rate)

"""# Teste e resultado"""

plt.scatter(x[:, 0], x[:, 1], c = result, s = 50, alpha = 0.5, cmap = '#1f77b4')

"""# Cluester Dataset"""

x_, y_ = datasets.make_blobs(n_samples = 400, n_features = 2, centers = 4, random_state = 10, cluster_std = 0.5,  shuffle = True)

plt.scatter(x_[:, 0], x_[:, 1], c = y_, s = 50, alpha = 0.7, cmap = 'cool')

hidden_neurons = 8
output_neurons = 4
learning_rate = 0.002
epochs = 50

modelo = Perceptron(x_,y_, hidden_neurons = hidden_neurons, output_neurons=output_neurons)
result = modelo.fit(100, 0.001)